---
layout: post
title: Simulating Likert Data for Attitude Survey
---

This is the beggining of a long journey I want to have finished by the time I complete my PhD.

# Motivation

There is an interplay between psychophysics, psychometrics, and attitude surveys, which goes way back. [Nunally and Bernstein](https://www.worldcat.org/title/psychometric-theory/oclc/193064) is where I first encountered this idea.

Something that has been always bugging me is that in the ["old"](https://journals.sagepub.com/doi/10.1177/0956797613504966) statistics domain, some great people had done the background work, be it in the 1930's or 1960's, and provided us with the recipes, and accompanying _tables_ [for instance](https://www.itl.nist.gov/div898/handbook/eda/section3/eda3674.htm), to make sense of our own data, in our own research applications.

	[And it is well known to what kind of woes this has lead](https://www.apa.org/science/leadership/bsa/statistical)
It is no secret that any modern computer's power renders this approach obsolete. [Revelle](https://www.researchgate.net/publication/326136417_Reliability_from_alpha_to_omega_a_tutorial) makes this point quite clear for assessing reliability.

The long and short of this idea is that there is no need for benchmarks and shortcuts of the kind, because we have computers.

## Now, what to do with a computer once we have one

When psychologists do research, they tend to not know the actual state of affairs in the social world.

During my undergraduate studies I used to think "this is good enough". For example, when producing a Cronbach's $\alpha$, a correlation matrix, a Varimax PCA, and some $F_{df1,df2}$ from ANOVA's, I would think "that's as far as quantification can go for psych, and is impressive as it is."

_(To be fair most people I know don't even suspect that even this level of quantification goes on in psychology, but anyway, there is way more to it. For example [Anderson's ACT-R 6 simulations](http://act-r.psy.cmu.edu/) blew my mind! I will come back to this in another post.)_

Now, the thing is that computers allow us to **simulate** different states of affairs. This can go a long way. We can simulate statistical distributions, i.e. the populations from which we draw our samples. Or the cognitive architecture of one, or more, agents, interacting with each other.

For instance [Beaujean](https://scholarworks.umass.edu/cgi/viewcontent.cgi?article=1324&context=pare) provides some examples for assessing the accuracy of parameter estimates for SEM models in R.

[Revelle](https://personality-project.org/r/psych/help/sim.html) provides a number of `sim` functions in his `psych` package, which generate data according to different underlying structures (you can run `example(sim.hierarchical)` in an R console)

[Chalmers](https://rdrr.io/cran/mirt/man/simdata.html) has also provided a simulation function for [Multidimensional IRT](https://www.frontiersin.org/articles/10.3389/feduc.2019.00045/full)

# Direction

So I have been thinking a lot about this, and I decided to delve into it. I figured the time spent on my PhD would be better go into something like this, rather than use some out-of-the-box solutions I already know how to use _practically_.

Ideally, when I do the analysis of the final study of my PhD, I will be in the position to say

	If the data I collected are drawn from a population with _this_ structure, estimating parameters a, b, c, ..., is _that_ accurate, with a sample of this size.
